"""functional_connectivity.py

Compute Global Functional Connectivity (GFC) and a simple modularity metric
from parcel‑wise fMRI time‑series.

This general‑purpose CLI tool converts a *timeseries.pkl* (generated by
`extract_timeseries.py`) into subject‑level summary metrics:

* **GFC** – Mean absolute Pearson correlation across all parcel pairs.
* **Modularity** – Difference between mean within‑network FC and mean
  between‑network FC (requires a network‑mapping file).

The script is atlas‑agnostic: all that matters is that the network‑mapping
file (if provided) matches the order of parcels in the time‑series arrays.

Example
-------

python functional_connectivity.py \
    --timeseries timeseries_music.pkl \
    --network-map schaefer100_yeo7.tsv \
    --out-dir metrics/

Each subject receives two rows in *global_fc.tsv* and *modularity.tsv*
(one per experimental condition/group).

Network mapping
---------------

Provide a TSV or CSV with **two columns**:

| parcel | network |
|--------|---------|
| 0      | Vis     |
| 1      | Vis     |
| 2      | SomMot  |
| ...    | ...     |

If your parcellation’s label file already includes network tags embedded in
the parcel names (e.g. “Vis_1”, “Cont_13”), you can pass the same file here –
the script will automatically parse the second column.

Requirements
------------
numpy, pandas, scipy, tqdm

"""

from __future__ import annotations
import argparse
from pathlib import Path
import pickle
from typing import Dict, List

import numpy as np
import pandas as pd
from scipy.stats import zscore
from tqdm import tqdm


def parse_cli() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Compute GFC / Modularity metrics.")
    parser.add_argument(
        "--timeseries", required=True, type=Path,
        help="Pickle file produced by extract_timeseries.py")
    parser.add_argument(
        "--network-map", type=Path, default=None,
        help="Optional TSV / CSV mapping parcels → network names.")
    parser.add_argument(
        "--out-dir", type=Path, default=Path("metrics"),
        help="Directory where summary tables will be written.")
    return parser.parse_args()


# -----------------------------------------------------------------------------#
#                                Helper funcs                                  #
# -----------------------------------------------------------------------------#

def load_network_map(path: Path) -> List[str]:
    """Return a list mapping parcel index → network label."""
    df = pd.read_csv(path, sep=None, engine="python", header=None, names=["parcel", "network"])
    # If first column looks numeric and second column categorical, accept as-is.
    if df["parcel"].dtype.kind in "iuf":
        df = df.sort_values("parcel")
        labels = df["network"].tolist()
    else:
        # Assume the entire file is a single column of labels in parcel order
        labels = df["parcel"].tolist()
    return labels


def correlation_matrix(ts: np.ndarray) -> np.ndarray:
    """Compute Pearson correlation on (T, P) array, returns (P, P)."""
    ts_z = zscore(ts, axis=0)
    return np.corrcoef(ts_z, rowvar=False)


def mean_abs_upper(mat: np.ndarray) -> float:
    idx = np.triu_indices_from(mat, k=1)
    return float(np.mean(np.abs(mat[idx])))


def modularity_metric(mat: np.ndarray, networks: List[str]) -> float:
    """Simplified modularity: within – between FC (absolute, upper triangle)."""
    n = len(networks)
    idx_upper = np.triu_indices(n, k=1)
    within_vals = []
    between_vals = []
    for i, j in zip(*idx_upper):
        (within_vals if networks[i] == networks[j] else between_vals).append(mat[i, j])
    return float(np.mean(within_vals) - np.mean(between_vals))


# -----------------------------------------------------------------------------#
#                                  Main logic                                  #
# -----------------------------------------------------------------------------#

def main():
    args = parse_cli()
    args.out_dir.mkdir(parents=True, exist_ok=True)

    # Load data
    with open(args.timeseries, "rb") as fp:
        ts_dict: Dict[str, Dict[str, np.ndarray]] = pickle.load(fp)

    network_labels: List[str] | None = None
    if args.network_map:
        network_labels = load_network_map(args.network_map)

    gfc_rows = []
    mod_rows = []

    for group, subjects in ts_dict.items():
        for subj, ts in tqdm(subjects.items(), desc=f"Processing {group}"):
            corr = correlation_matrix(ts)
            gfc_val = mean_abs_upper(corr)
            gfc_rows.append({"group": group, "subject": subj, "gfc": gfc_val})

            if network_labels:
                if len(network_labels) != corr.shape[0]:
                    raise ValueError("Network map length does not match number of parcels.")
                mod_val = modularity_metric(corr, network_labels)
                mod_rows.append({"group": group, "subject": subj, "modularity": mod_val})

    pd.DataFrame(gfc_rows).to_csv(args.out_dir / "global_fc.tsv", sep="\t", index=False)
    if mod_rows:
        pd.DataFrame(mod_rows).to_csv(args.out_dir / "modularity.tsv", sep="\t", index=False)

    print("Analysis complete. Results saved to", args.out_dir.resolve())


if __name__ == "__main__":
    main()
